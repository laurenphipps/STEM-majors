{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_features = ['X2SEX', 'X2RACE', 'X2DUALLANG', 'X2POVERTY185', 'X2SESQ5_U', 'X2CONTROL', 'X2LOCALE', 'X2REGION']\n",
    "\n",
    "\n",
    "mvp_features = ['X2STU30OCC_STEM1', 'X2STUEDEXPCT', 'X2S2SSPR12', 'S2SPERSON1', 'S2SPERSON2', \n",
    "               'S2SLEARN', 'S2SBORN', 'S2SUSELIFE', 'S2SUSECLG', 'S2SUSEJOB', \n",
    "               'S2SSPR12', 'S2LIFES12', 'S2BIO1S12', 'S2BIO2S12', 'S2APBIOS12', \n",
    "               'S2IBIOS12', 'S2ANATOMYS12', 'S2OTHBIOS12', 'S2CHEM1S12', 'S2CHEM2S12', 'S2APCHEM12', \n",
    "               'S2IBCHEM12', 'S2EARTHS12', 'S2APENVS12', 'S2OTHENVS12', 'S2PHYSIC1S12', \n",
    "               'S2PHYSIC2S12', 'S2APPHYSIC12', 'S2IBPHYSIC12', 'S2PHYSS12', 'S2TECHS12', 'S2OTHPHYS12', \n",
    "               'S2INTGS1S12', 'S2INTGS2S12', 'S2GENS12', 'S2COMPAPP12', 'S2COMPPROG12', \n",
    "               'S2APCOMPSCI12', 'S2IBTECH12', 'S2OTHCOMP12', 'S2ENGINEER12', 'S2OTHS12', 'S2OTHS12SP', \n",
    "               'S2HISCIENCE12', 'S2APSCIENCE', 'S2IBSCIENCE', 'S2STOOKBEFORE', 'S2SENJOYS', 'S2SCHALLENGE', 'S2SHSREQ', 'S2SCLGADM', \n",
    "               'S2SCLGSUCC', 'S2SCAREER', 'S2SCNSLREC', 'S2STCHRREC', 'S2SPARREC', 'S2SFAMREC', \n",
    "               'S2SEMPREC', 'S2SFRIEND', 'S2SDOWELL', 'S2SASSIGNED', 'S2STCHTREAT', 'S2STCHINTRST', \n",
    "               'S2STCHEASY', 'S2STCHTHINK', 'S2STCHGIVEUP', 'S2SENJOYING', 'S2SWASTE', 'S2SBORING', \n",
    "               'S2SUSELIFE', 'S2SUSECLG', 'S2SUSEJOB', 'S2STESTS', 'S2STEXTBOOK', 'S2SSKILLS', \n",
    "               'S2SASSEXCL', 'S2APSCIENCE', 'S2HSPLAN', 'S2SUBMITPLAN', 'S2SCLUB', \n",
    "            'S2SCOMPETE', 'S2SSUMMERPRG', 'S2SGROUP', 'S2STUTORED', 'X4RFDGMJ123', 'X4RFDGMJSTEM']\n",
    "\n",
    "family_features = ['X2PAR1EDU', 'X2PAR1OCC_STEM1', \n",
    "            'X2PAR1RACE', 'X2PAR2EDU', 'X2PAR2OCC_STEM1', 'X2PAR2RACE', 'X2PARPATTERN', \n",
    "            'X2MOMEDU', 'X2MOMOCC_STEM1', 'X2MOMRACE', 'X2DADEDU', 'X2DADOCC_STEM1', \n",
    "            'X2DADRACE']\n",
    "\n",
    "cols_list = demo_features + mvp_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data-files/HSLS/hsls_17_student_pets_sr_v1_0.csv', usecols = cols_list)\n",
    "df.rename(columns = {'X4RFDGMJSTEM': 'target'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with non-response to S2SLEARN (and many other features) (likely dropped from study)\n",
    "df = df[df['S2SLEARN'] != -8]\n",
    "\n",
    "#create dummy variables for races\n",
    "df['ai_an'] = np.where(df['X2RACE'] == 1, 1, 0)\n",
    "df['asian'] = np.where(df['X2RACE'] == 2, 1, 0)\n",
    "df['black'] = np.where(df['X2RACE'] == 3, 1, 0)\n",
    "df['hispanic'] = np.where((df['X2RACE'] == 4) | (df['X2RACE'] == 5), 1, 0)\n",
    "df['multiple_race'] = np.where(df['X2RACE'] == 6, 1, 0)\n",
    "df['nh_pi'] = np.where(df['X2RACE'] == 7, 1, 0)\n",
    "df['white'] = np.where(df['X2RACE'] == 8, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'X2DUALLANG', 'X2POVERTY185', 'X2SESQ5_U', 'X2CONTROL', 'X2LOCALE', 'X2REGION'\n",
    "\n",
    "#create dummy for public/private school\n",
    "df['private'] = [1 if x == 2 else 0 for x in df['X2CONTROL']]\n",
    "df['public'] = [1 if x == 1 else 0 for x in df['X2CONTROL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile all subchoices of STEM domains into yes/no\n",
    "df.X2STU30OCC_STEM1.replace({-9:0, 9:0, 4:1, 5:1, 6:1}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['S2SSPR12', 'S2LIFES12', 'S2BIO1S12', 'S2BIO2S12', 'S2APBIOS12', \n",
    "               'S2IBIOS12', 'S2ANATOMYS12', 'S2OTHBIOS12', 'S2CHEM1S12', 'S2CHEM2S12', 'S2APCHEM12', \n",
    "               'S2IBCHEM12', 'S2EARTHS12', 'S2APENVS12', 'S2OTHENVS12', 'S2PHYSIC1S12', \n",
    "               'S2PHYSIC2S12', 'S2APPHYSIC12', 'S2IBPHYSIC12', 'S2PHYSS12', 'S2TECHS12', 'S2OTHPHYS12', \n",
    "               'S2INTGS1S12', 'S2INTGS2S12', 'S2GENS12', 'S2COMPAPP12', 'S2COMPPROG12', \n",
    "               'S2APCOMPSCI12', 'S2IBTECH12', 'S2OTHCOMP12', 'S2ENGINEER12', 'S2OTHS12', 'S2APSCIENCE', 'S2IBSCIENCE']\n",
    "\n",
    "#impute 'no' for items that are missing or were skipped due to not taking a science class\n",
    "for col in classes:\n",
    "    df[col].replace({-9:0, -7:0}, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16192\n",
       "0     4402\n",
       "Name: S2SSPR12, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.S2SSPR12.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute unknown with 'no' for if participating in science activity\n",
    "\n",
    "clubs_cols = ['S2SCLUB', 'S2SCOMPETE', 'S2SSUMMERPRG', 'S2SGROUP', 'S2STUTORED']\n",
    "\n",
    "for col in clubs_cols:\n",
    "    df[col].replace({-9:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.S2HSPLAN = np.where(df['S2HSPLAN'] == 1, 1, 0)\n",
    "df.S2SUBMITPLAN = np.where(df['S2SUBMITPLAN'] == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class for underrepresented group in STEM (women, black, american indian, hispanic, pacific islander)\n",
    "\n",
    "df['underrep'] = np.where((df['X2SEX'] == 2) |\n",
    "                          (df['ai_an'] == 1) |\n",
    "                          (df['black'] == 1) |\n",
    "                          (df['hispanic'] == 1) |\n",
    "                          (df['multiple_race'] == 1) |\n",
    "                          (df['nh_pi'] == 1), 1, 0)\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group HS science classes into broader subjects\n",
    "\n",
    "df['bio'] = np.where((df['S2LIFES12'] == 1) |\n",
    "                      (df['S2BIO1S12'] == 1) |\n",
    "                      (df['S2BIO2S12'] == 1) |\n",
    "                      (df['S2APBIOS12'] == 1) |\n",
    "                      (df['S2IBIOS12'] == 1) |\n",
    "                     (df['S2ANATOMYS12'] == 1) |\n",
    "                      (df['S2OTHBIOS12'] == 1), 1, 0)\n",
    "               \n",
    "\n",
    "df['chem'] = np.where((df['S2CHEM1S12'] == 1) |\n",
    "                      (df['S2CHEM2S12'] == 1) |\n",
    "                      (df['S2APCHEM12'] == 1) |\n",
    "                      (df['S2IBCHEM12'] == 1), 1, 0)\n",
    "              \n",
    "\n",
    "df['enviro'] = np.where((df['S2EARTHS12'] == 1) |\n",
    "                        (df['S2EARTHS12'] == 1) |\n",
    "                        (df['S2APENVS12'] == 1) |\n",
    "                        (df['S2OTHENVS12'] == 1), 1, 0)\n",
    "                        \n",
    "df['physics'] = np.where((df['S2PHYSIC1S12'] == 1) |\n",
    "                         (df['S2PHYSIC2S12'] == 1) |\n",
    "                         (df['S2APPHYSIC12'] == 1) |\n",
    "                         (df['S2IBPHYSIC12'] == 1) |\n",
    "                         (df['S2PHYSS12'] == 1), 1, 0)\n",
    "                         \n",
    "df['engineering'] = np.where((df['S2ENGINEER12'] == 1), 1, 0)\n",
    "\n",
    "\n",
    "df['compsci'] = np.where((df['S2COMPAPP12'] == 1) |\n",
    "                         (df['S2COMPPROG12'] == 1) |\n",
    "                         (df['S2APCOMPSCI12'] == 1) |\n",
    "                         (df['S2IBTECH12'] == 1) |\n",
    "                         (df['S2OTHCOMP12'] == 1), 1, 0)\n",
    "\n",
    "df['misc_class'] = np.where((df['S2OTHPHYS12'] == 1) |\n",
    "                            (df['S2INTGS1S12'] == 1) |\n",
    "                            (df['S2GENS12'] == 1), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create column for students who took science earlier in the year (but don't now)\n",
    "df['took_science_2012'] = np.where((df['S2STOOKBEFORE'] == 1) |\n",
    "                                   (df['bio'] == 1) |\n",
    "                                   (df['chem'] == 1) |\n",
    "                                   (df['enviro'] == 1) |\n",
    "                                   (df['physics'] == 1) |\n",
    "                                   (df['engineering'] == 1) |\n",
    "                                   (df['compsci'] == 1) |\n",
    "                                   (df['misc_class'] == 1), 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18051\n",
       "0     2543\n",
       "Name: took_science_2012, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.took_science_2012.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute 'no' for items that are missing or were skipped due to not taking a science class\n",
    "\n",
    "why_science = ['S2SENJOYS', 'S2SCHALLENGE', 'S2SHSREQ', 'S2SCLGADM', \n",
    "               'S2SCLGSUCC', 'S2SCAREER', 'S2SCNSLREC', 'S2STCHRREC', 'S2SPARREC', 'S2SFAMREC', \n",
    "               'S2SEMPREC', 'S2SFRIEND', 'S2SDOWELL', 'S2SASSIGNED']\n",
    "\n",
    "for col in why_science:\n",
    "    df[col].replace({-9:0, -7:0}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with target variable\n",
    "modeling_df = df[(df.target == 0) | (df.target == 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "likert_cols = ['S2SPERSON1', 'S2SPERSON2', \n",
    "               'S2SLEARN', 'S2SBORN', 'S2SUSELIFE', 'S2SUSECLG', 'S2SUSEJOB', \n",
    "                'S2STCHTREAT', 'S2STCHINTRST', \n",
    "               'S2STCHEASY', 'S2STCHTHINK', 'S2STCHGIVEUP', 'S2SENJOYING', 'S2SWASTE', 'S2SBORING', \n",
    "               'S2STESTS', 'S2STEXTBOOK', 'S2SSKILLS', \n",
    "               'S2SASSEXCL']\n",
    "\n",
    "#change likert questions to agree/disagree\n",
    "for col in likert_cols:\n",
    "   modeling_df[col].replace({2:1, 3:0, 4:0, -9:0, }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9381\n",
       "0    1593\n",
       "Name: S2SSPR12, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.S2SSPR12.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target  underrep  took_science_2012\n",
       "0       0         1                    0.913410\n",
       "                  0                    0.086590\n",
       "        1         1                    0.916964\n",
       "                  0                    0.083036\n",
       "1       0         1                    0.955943\n",
       "                  0                    0.044057\n",
       "        1         1                    0.945307\n",
       "                  0                    0.054693\n",
       "Name: took_science_2012, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.groupby(by = ['target', 'underrep']).took_science_2012.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7519\n",
       "0    3455\n",
       "Name: underrep, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.underrep.value_counts(normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "underrep_df = modeling_df[modeling_df['underrep'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model - ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = modeling_df.drop(columns = 'target', axis =1)\n",
    "y = modeling_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['S2SCLUB', 'S2SCOMPETE', 'S2SSUMMERPRG', 'S2SGROUP', 'S2STUTORED', 'S2SPERSON1', 'S2SPERSON2', \n",
    "               'S2SLEARN', 'S2SBORN', 'S2SUSELIFE', 'S2SUSECLG', 'S2SUSEJOB', 'S2SENJOYING', 'S2SWASTE', 'S2SBORING', \n",
    "               'S2STESTS', 'S2STEXTBOOK', 'S2SSKILLS', \n",
    "               'S2SASSEXCL', 'S2SENJOYS', 'S2SCHALLENGE', 'S2SHSREQ', 'S2SCLGADM', \n",
    "               'S2SCLGSUCC', 'S2SCAREER', 'S2SCNSLREC', 'S2STCHRREC', 'S2SPARREC', 'S2SFAMREC', \n",
    "               'S2SEMPREC', 'S2SFRIEND', 'S2SDOWELL', 'S2SASSIGNED', 'X2STU30OCC_STEM1', 'took_science_2012', \n",
    "            'bio', 'chem', 'enviro', 'physics', 'engineering', 'compsci', 'misc_class']\n",
    "                            \n",
    "\n",
    "lr_fsm = LogisticRegression(max_iter = 10000, C = 10000, random_state = 20, class_weight = 'balanced')\n",
    "lr_fsm.fit(X_train[features], y_train)\n",
    "\n",
    "train_pred = lr_fsm.predict(X_train[features])\n",
    "test_pred = lr_fsm.predict(X_test[features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 1.0800034284625175),\n",
       " ('compsci', 0.749149005655807),\n",
       " ('S2SSUMMERPRG', 0.5114422317776263),\n",
       " ('X2STU30OCC_STEM1', 0.4439532751689377),\n",
       " ('physics', 0.4224062256983904),\n",
       " ('S2SPERSON1', 0.41292629090935923),\n",
       " ('S2SUSEJOB', 0.3982328953938054),\n",
       " ('S2SENJOYS', 0.32533157942213087),\n",
       " ('S2SCOMPETE', 0.30201176544514324),\n",
       " ('S2SCLUB', 0.27036958671467864),\n",
       " ('S2SCAREER', 0.264377261115631),\n",
       " ('chem', 0.26320455546142757),\n",
       " ('S2SPERSON2', 0.2447810591299161),\n",
       " ('S2STESTS', 0.15010864609096158),\n",
       " ('S2STEXTBOOK', 0.1330724505107946),\n",
       " ('S2SPARREC', 0.1169965979478818),\n",
       " ('S2SFRIEND', 0.11477585106806153),\n",
       " ('S2SCHALLENGE', 0.05961811928306865),\n",
       " ('S2SDOWELL', 0.048807840305977124),\n",
       " ('S2SUSELIFE', 0.03386371374909636),\n",
       " ('S2SUSECLG', 0.028864228356104322),\n",
       " ('S2SLEARN', 0.021286941255627474),\n",
       " ('enviro', 0.019332243869965137),\n",
       " ('S2SEMPREC', 0.01822512491178271),\n",
       " ('S2SBORING', 0.007862841167269263),\n",
       " ('S2SCLGSUCC', 0.003725728266928981),\n",
       " ('S2SBORN', -0.00027722538543625326),\n",
       " ('bio', -0.011385394051612695),\n",
       " ('S2SENJOYING', -0.023157040540259913),\n",
       " ('S2SFAMREC', -0.02730384672319005),\n",
       " ('S2SSKILLS', -0.07032801690994739),\n",
       " ('S2SASSEXCL', -0.08039453824330511),\n",
       " ('S2SGROUP', -0.09308120261590314),\n",
       " ('S2SWASTE', -0.09861836274261537),\n",
       " ('S2SHSREQ', -0.10701949750518891),\n",
       " ('S2SCLGADM', -0.12899171472569637),\n",
       " ('S2SCNSLREC', -0.14098443115068574),\n",
       " ('S2STCHRREC', -0.1794361344126881),\n",
       " ('took_science_2012', -0.22100100680303117),\n",
       " ('S2SASSIGNED', -0.2244361735147479),\n",
       " ('S2STUTORED', -0.2840897157055982),\n",
       " ('misc_class', -0.4727084278288212)]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = dict(zip(list(features), list(lr_fsm.coef_[0])))\n",
    "sorted_dict1 = sorted(coef.items(), key=lambda kv: kv[1])\n",
    "sorted_dict1.reverse()\n",
    "sorted_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict = {}\n",
    "metric_dict['LogisticRegression'] = {'train_accuracy': metrics.accuracy_score(y_train, train_pred),\n",
    "                                      'test_accuracy': metrics.accuracy_score(y_test, test_pred),\n",
    "                                      'train_precision':metrics.precision_score(y_train, train_pred),\n",
    "                                      'test_precision':metrics.precision_score(y_test, test_pred),\n",
    "                                      'train_recall':metrics.recall_score(y_train, train_pred),\n",
    "                                      'test_recall':metrics.recall_score(y_test, test_pred),\n",
    "                                      'train_f1':metrics.f1_score(y_train, train_pred),\n",
    "                                      'test_f1':metrics.f1_score(y_test, test_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'train_accuracy': 0.6653377377833466,\n",
       "  'test_accuracy': 0.675626423690205,\n",
       "  'train_precision': 0.37809187279151946,\n",
       "  'test_precision': 0.3892013498312711,\n",
       "  'train_recall': 0.6815286624203821,\n",
       "  'test_recall': 0.6718446601941748,\n",
       "  'train_f1': 0.48636363636363633,\n",
       "  'test_f1': 0.4928774928774928}}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial - Underrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ur = underrep_df.drop(columns = 'target', axis =1)\n",
    "y_ur = underrep_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xu_train, Xu_test, yu_train, yu_test = train_test_split(X_ur, y_ur, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ur_fsm = LogisticRegression(max_iter = 10000, C = 10000, random_state = 20, class_weight = 'balanced')\n",
    "lr_ur_fsm.fit(Xu_train[features], yu_train)\n",
    "\n",
    "train_ur_pred = lr_ur_fsm.predict(Xu_train[features])\n",
    "test_ur_pred = lr_ur_fsm.predict(Xu_test[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 1.0069478063139476),\n",
       " ('compsci', 0.5925317094154284),\n",
       " ('S2SSUMMERPRG', 0.534649804103606),\n",
       " ('physics', 0.43336325195311043),\n",
       " ('S2SCLUB', 0.42591297871725736),\n",
       " ('X2STU30OCC_STEM1', 0.4150947394192837),\n",
       " ('S2SCAREER', 0.3731463020937605),\n",
       " ('S2SPERSON1', 0.3679358001415783),\n",
       " ('S2SPERSON2', 0.2888017421726653),\n",
       " ('S2SCOMPETE', 0.25570050057282634),\n",
       " ('S2SENJOYS', 0.23859686376098202),\n",
       " ('S2SUSELIFE', 0.23748736581418353),\n",
       " ('S2SUSEJOB', 0.1809791305812877),\n",
       " ('S2STEXTBOOK', 0.1668512834514574),\n",
       " ('S2SCHALLENGE', 0.15236417448424344),\n",
       " ('chem', 0.1478330708245279),\n",
       " ('S2STESTS', 0.09055178964727684),\n",
       " ('S2SCLGSUCC', 0.03273523212931524),\n",
       " ('S2SASSEXCL', 0.0318194047153499),\n",
       " ('S2SBORN', 0.031260714404630935),\n",
       " ('S2SPARREC', 0.02487793803996917),\n",
       " ('S2SDOWELL', 0.021624987706571955),\n",
       " ('S2SWASTE', 0.014501550508275224),\n",
       " ('S2SGROUP', 0.013854269936199792),\n",
       " ('enviro', 0.004538181305145458),\n",
       " ('S2SFRIEND', -0.005210993709941),\n",
       " ('S2SBORING', -0.007787029324933782),\n",
       " ('S2SSKILLS', -0.012668968350946198),\n",
       " ('S2SLEARN', -0.017936094704245478),\n",
       " ('bio', -0.02281950258874519),\n",
       " ('took_science_2012', -0.044920130142610884),\n",
       " ('S2SFAMREC', -0.05290123125778445),\n",
       " ('S2SCLGADM', -0.054373646205124075),\n",
       " ('S2STCHRREC', -0.08226939001124892),\n",
       " ('S2SENJOYING', -0.10376438674492627),\n",
       " ('S2SASSIGNED', -0.15866112164578747),\n",
       " ('S2SUSECLG', -0.1711606336431809),\n",
       " ('S2STUTORED', -0.2113158121069447),\n",
       " ('S2SHSREQ', -0.2244444273404107),\n",
       " ('S2SCNSLREC', -0.306742614370214),\n",
       " ('S2SEMPREC', -0.3279596796020538),\n",
       " ('misc_class', -0.7856678435667023)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = dict(zip(list(features), list(lr_ur_fsm.coef_[0])))\n",
    "sorted_dict1 = sorted(coef.items(), key=lambda kv: kv[1])\n",
    "sorted_dict1.reverse()\n",
    "sorted_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict['URLogisticRegression'] = {'train_accuracy': metrics.accuracy_score(yu_train, train_ur_pred),\n",
    "                                      'test_accuracy': metrics.accuracy_score(yu_test, test_ur_pred),\n",
    "                                      'train_precision':metrics.precision_score(yu_train, train_ur_pred),\n",
    "                                      'test_precision':metrics.precision_score(yu_test, test_ur_pred),\n",
    "                                      'train_recall':metrics.recall_score(yu_train, train_ur_pred),\n",
    "                                      'test_recall':metrics.recall_score(yu_test, test_ur_pred),\n",
    "                                      'train_f1':metrics.f1_score(yu_train, train_ur_pred),\n",
    "                                      'test_f1':metrics.f1_score(yu_test, test_ur_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'train_accuracy': 0.6653377377833466,\n",
       "  'test_accuracy': 0.675626423690205,\n",
       "  'train_precision': 0.37809187279151946,\n",
       "  'test_precision': 0.3892013498312711,\n",
       "  'train_recall': 0.6815286624203821,\n",
       "  'test_recall': 0.6718446601941748,\n",
       "  'train_f1': 0.48636363636363633,\n",
       "  'test_f1': 0.4928774928774928},\n",
       " 'URLogisticRegression': {'train_accuracy': 0.6761429758935993,\n",
       "  'test_accuracy': 0.660904255319149,\n",
       "  'train_precision': 0.3169164882226981,\n",
       "  'test_precision': 0.2895622895622896,\n",
       "  'train_recall': 0.6770356816102471,\n",
       "  'test_recall': 0.6615384615384615,\n",
       "  'train_f1': 0.43173862310385064,\n",
       "  'test_f1': 0.4028103044496487}}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrep_df = modeling_df[modeling_df['underrep'] == 0]\n",
    "\n",
    "X_or = overrep_df.drop(columns = 'target', axis =1)\n",
    "y_or = overrep_df['target']\n",
    "\n",
    "Xo_train, Xo_test, yo_train, yo_test = train_test_split(X_or, y_or, test_size = 0.2, random_state = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_or_fsm = LogisticRegression(max_iter = 10000, C = 10000, random_state = 20, class_weight = 'balanced')\n",
    "lr_or_fsm.fit(Xo_train[features], yo_train)\n",
    "\n",
    "train_or_pred = lr_or_fsm.predict(Xo_train[features])\n",
    "test_or_pred = lr_or_fsm.predict(Xo_test[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 0.8991879517434294),\n",
       " ('X2STU30OCC_STEM1', 0.7884251810784615),\n",
       " ('compsci', 0.7374946980860351),\n",
       " ('misc_class', 0.488614000410563),\n",
       " ('chem', 0.46008807743137237),\n",
       " ('physics', 0.4509259654525843),\n",
       " ('S2SUSEJOB', 0.42230533827532146),\n",
       " ('S2SCLUB', 0.40804835875837797),\n",
       " ('S2SSUMMERPRG', 0.3419779430595667),\n",
       " ('S2SCOMPETE', 0.3363554749664277),\n",
       " ('S2SCAREER', 0.30012483934301565),\n",
       " ('S2SEMPREC', 0.2993959742930527),\n",
       " ('S2SPERSON1', 0.26031753136331637),\n",
       " ('S2SDOWELL', 0.24095621854593047),\n",
       " ('S2SPERSON2', 0.22639342441071664),\n",
       " ('S2SENJOYS', 0.21655077610709317),\n",
       " ('S2SPARREC', 0.14805476642010468),\n",
       " ('enviro', 0.13977292897516425),\n",
       " ('S2SCHALLENGE', 0.1169655190176675),\n",
       " ('S2SUSECLG', 0.07975729210479916),\n",
       " ('S2SENJOYING', 0.07697818480098213),\n",
       " ('S2SLEARN', 0.06283512816380846),\n",
       " ('bio', 0.035903599414143055),\n",
       " ('S2STESTS', 0.02637598237083904),\n",
       " ('S2SHSREQ', 0.02482555396136357),\n",
       " ('S2SBORN', 0.01503685961630344),\n",
       " ('S2STCHRREC', 0.005633699730942853),\n",
       " ('S2SFAMREC', -0.009144265021269015),\n",
       " ('S2SCLGSUCC', -0.01850227973252539),\n",
       " ('S2SSKILLS', -0.03913516895969785),\n",
       " ('S2SFRIEND', -0.055809829775924316),\n",
       " ('S2STEXTBOOK', -0.06523795576154633),\n",
       " ('S2SASSIGNED', -0.13142960516373212),\n",
       " ('S2SUSELIFE', -0.14134204927019492),\n",
       " ('S2SBORING', -0.1589597576569506),\n",
       " ('S2SASSEXCL', -0.1639089436827463),\n",
       " ('S2SCNSLREC', -0.1751295910596004),\n",
       " ('S2STUTORED', -0.18704884669605024),\n",
       " ('S2SGROUP', -0.19515369444014916),\n",
       " ('took_science_2012', -0.2979147779664159),\n",
       " ('S2SWASTE', -0.3339104249757297),\n",
       " ('S2SCLGADM', -0.33455939278007163)]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = dict(zip(list(features), list(lr_or_fsm.coef_[0])))\n",
    "sorted_dict1 = sorted(coef.items(), key=lambda kv: kv[1])\n",
    "sorted_dict1.reverse()\n",
    "sorted_dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dict['ORLogisticRegression'] = {'train_accuracy': metrics.accuracy_score(yo_train, train_or_pred),\n",
    "                                      'test_accuracy': metrics.accuracy_score(yo_test, test_or_pred),\n",
    "                                      'train_precision':metrics.precision_score(yo_train, train_or_pred),\n",
    "                                      'test_precision':metrics.precision_score(yo_test, test_or_pred),\n",
    "                                      'train_recall':metrics.recall_score(yo_train, train_or_pred),\n",
    "                                      'test_recall':metrics.recall_score(yo_test, test_or_pred),\n",
    "                                      'train_f1':metrics.f1_score(yo_train, train_or_pred),\n",
    "                                      'test_f1':metrics.f1_score(yo_test, test_or_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'train_accuracy': 0.6653377377833466,\n",
       "  'test_accuracy': 0.675626423690205,\n",
       "  'train_precision': 0.37809187279151946,\n",
       "  'test_precision': 0.3892013498312711,\n",
       "  'train_recall': 0.6815286624203821,\n",
       "  'test_recall': 0.6718446601941748,\n",
       "  'train_f1': 0.48636363636363633,\n",
       "  'test_f1': 0.4928774928774928},\n",
       " 'URLogisticRegression': {'train_accuracy': 0.6761429758935993,\n",
       "  'test_accuracy': 0.660904255319149,\n",
       "  'train_precision': 0.3169164882226981,\n",
       "  'test_precision': 0.2895622895622896,\n",
       "  'train_recall': 0.6770356816102471,\n",
       "  'test_recall': 0.6615384615384615,\n",
       "  'train_f1': 0.43173862310385064,\n",
       "  'test_f1': 0.4028103044496487},\n",
       " 'ORLogisticRegression': {'train_accuracy': 0.6903039073806078,\n",
       "  'test_accuracy': 0.6845151953690304,\n",
       "  'train_precision': 0.5498366013071896,\n",
       "  'test_precision': 0.5121107266435986,\n",
       "  'train_recall': 0.6881390593047034,\n",
       "  'test_recall': 0.6577777777777778,\n",
       "  'train_f1': 0.6112624886466849,\n",
       "  'test_f1': 0.5758754863813229}}"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
