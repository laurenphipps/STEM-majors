{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf1 as cf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cf.import_it('../data-files/HSLS/hsls_17_student_pets_sr_v1_0.csv')\n",
    "df = cf.clean_it(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.target == 1) | (df.target == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create df for subgroups\n",
    "\n",
    "female = df[df.female == 1]\n",
    "black = df[df.black == 1]\n",
    "hispanic = df[df.hispanic == 1]\n",
    "\n",
    "#select features for modeling\n",
    "features = ['S2SCLUB', 'S2SCOMPETE', 'S2SSUMMERPRG', 'S2SGROUP', 'S2STUTORED', 'S2SPERSON1', 'S2SPERSON2', \n",
    "               'S2SLEARN', 'S2SBORN', 'S2SUSELIFE', 'S2SUSECLG', 'S2SUSEJOB', 'S2SENJOYING', 'S2SWASTE', 'S2SBORING', \n",
    "               'S2STESTS', 'S2STEXTBOOK', 'S2SSKILLS', 'S2STCHTREAT', 'S2STCHINTRST', \n",
    "               'S2STCHEASY', 'S2STCHTHINK', 'S2STCHGIVEUP',\n",
    "               'S2SASSEXCL', 'S2SENJOYS', 'S2SCHALLENGE', 'S2SHSREQ', 'S2SCLGADM', \n",
    "               'S2SCLGSUCC', 'S2SCAREER', 'S2SCNSLREC', 'S2STCHRREC', 'S2SPARREC', 'S2SFAMREC', \n",
    "               'S2SEMPREC', 'S2SFRIEND', 'S2SDOWELL', 'S2SASSIGNED', 'X2STU30OCC_STEM1', 'took_science_2012',  \n",
    "            'bio', 'chem', 'enviro', 'physics', 'engineering', 'compsci', 'misc_class', 'public', 'black', 'hispanic', 'asian', 'ai_an', 'multiple_race', 'nh_pi' , 'X2POVERTY185', 'underrep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6009, 110)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1004, 110)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1486, 110)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hispanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Female Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split\n",
    "X = female.drop(columns = 'target', axis =1)\n",
    "X = X[features]\n",
    "y = female['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run baseline\n",
    "lr_female_base = LogisticRegression(max_iter = 10000, random_state = 20)\n",
    "\n",
    "lr_female_base.fit(X_train, y_train)\n",
    "\n",
    "trainpred_lr_female_base = lr_female_base.predict(X_train)\n",
    "testpred_lr_female_base = lr_female_base.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': 0.8508425213230705,\n",
       " 'test_accuracy': 0.8469217970049917,\n",
       " 'train_precision': 0.6132075471698113,\n",
       " 'test_precision': 0.44680851063829785,\n",
       " 'train_recall': 0.16993464052287582,\n",
       " 'test_recall': 0.11731843575418995,\n",
       " 'train_f1': 0.26612077789150457,\n",
       " 'test_f1': 0.18584070796460175}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_dict = {}\n",
    "female_dict['Initial_LogisticRegression'] = {'train_accuracy': metrics.accuracy_score(y_train, trainpred_lr_female_base),\n",
    "                                      'test_accuracy': metrics.accuracy_score(y_test, testpred_lr_female_base),\n",
    "                                      'train_precision':metrics.precision_score(y_train, trainpred_lr_female_base),\n",
    "                                      'test_precision':metrics.precision_score(y_test, testpred_lr_female_base),\n",
    "                                      'train_recall':metrics.recall_score(y_train, trainpred_lr_female_base),\n",
    "                                      'test_recall':metrics.recall_score(y_test, testpred_lr_female_base),\n",
    "                                      'train_f1':metrics.f1_score(y_train, trainpred_lr_female_base),\n",
    "                                      'test_f1':metrics.f1_score(y_test, testpred_lr_female_base) \n",
    "                                          }\n",
    "\n",
    "female_dict['Initial_LogisticRegression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   47.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.69, 'class_weight': 'balanced', 'max_iter': 125}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##run gridsearch\n",
    "#instantiate classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "#select hyperparameter values to test\n",
    "param_grid = {\n",
    "    \n",
    "    'max_iter': [125, 130, 135, 150],\n",
    "    'C': [0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73], \n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "#run gridsearch with hyperparamters\n",
    "gs_LR = GridSearchCV(clf, param_grid, cv=5, scoring = 'f1', n_jobs = -1, verbose = 2)\n",
    "#fit the model to the train set\n",
    "gs_LR.fit(X_train, y_train)\n",
    "#get the best parameters\n",
    "gs_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_female_gs = LogisticRegression(C = 0.66, class_weight = 'balanced', max_iter = 125, random_state = 20)\n",
    "\n",
    "lr_female_gs.fit(X_train, y_train)\n",
    "\n",
    "trainpred_lr_female_gs = lr_female_gs.predict(X_train)\n",
    "testpred_lr_female_gs = lr_female_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': 0.7079259413355523,\n",
       " 'test_accuracy': 0.6788685524126455,\n",
       " 'train_precision': 0.3117265763111373,\n",
       " 'test_precision': 0.26096997690531176,\n",
       " 'train_recall': 0.6915032679738562,\n",
       " 'test_recall': 0.6312849162011173,\n",
       " 'train_f1': 0.42973192526401294,\n",
       " 'test_f1': 0.369281045751634}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_dict['GS_LogisticRegression'] = {'train_accuracy': metrics.accuracy_score(y_train, trainpred_lr_female_gs),\n",
    "                                      'test_accuracy': metrics.accuracy_score(y_test, testpred_lr_female_gs),\n",
    "                                      'train_precision':metrics.precision_score(y_train, trainpred_lr_female_gs),\n",
    "                                      'test_precision':metrics.precision_score(y_test, testpred_lr_female_gs),\n",
    "                                      'train_recall':metrics.recall_score(y_train, trainpred_lr_female_gs),\n",
    "                                      'test_recall':metrics.recall_score(y_test, testpred_lr_female_gs),\n",
    "                                      'train_f1':metrics.f1_score(y_train, trainpred_lr_female_gs),\n",
    "                                      'test_f1':metrics.f1_score(y_test, testpred_lr_female_gs) \n",
    "                                          }\n",
    "\n",
    "female_dict['GS_LogisticRegression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 1.0921259279641178),\n",
       " ('asian', 1.0350069495321625),\n",
       " ('physics', 0.7477033939041822),\n",
       " ('S2SCAREER', 0.4880740039669265),\n",
       " ('S2SCLUB', 0.48748480013492546),\n",
       " ('compsci', 0.44757604933703893),\n",
       " ('S2SPERSON1', 0.43722716575541737),\n",
       " ('S2SSUMMERPRG', 0.40270322618349214),\n",
       " ('S2SENJOYS', 0.3425651970380277),\n",
       " ('X2STU30OCC_STEM1', 0.3375336927920853),\n",
       " ('multiple_race', 0.3099931931337489),\n",
       " ('S2SPERSON2', 0.30600932298123906),\n",
       " ('chem', 0.2965243159492922),\n",
       " ('S2STEXTBOOK', 0.2944854104725567),\n",
       " ('nh_pi', 0.2383664076102029),\n",
       " ('S2STCHGIVEUP', 0.23108574880541433),\n",
       " ('ai_an', 0.20943622655215677),\n",
       " ('hispanic', 0.1984329615299881),\n",
       " ('S2SCOMPETE', 0.18978185383243323),\n",
       " ('S2SDOWELL', 0.17892702903591928),\n",
       " ('S2SUSEJOB', 0.15970566991865495),\n",
       " ('S2SFAMREC', 0.14455111631003317),\n",
       " ('S2SPARREC', 0.10411029282559807),\n",
       " ('black', 0.08988487710295782),\n",
       " ('S2STCHEASY', 0.08632086305103095),\n",
       " ('enviro', 0.07812139953453993),\n",
       " ('S2STESTS', 0.06274155292941234),\n",
       " ('bio', 0.059610975518713805),\n",
       " ('public', 0.05856066258990508),\n",
       " ('S2SCHALLENGE', 0.04939605230824909),\n",
       " ('S2SUSELIFE', 0.04720921240653823),\n",
       " ('S2SGROUP', 0.0273855754830046),\n",
       " ('S2SCLGSUCC', 0.013151525797208357),\n",
       " ('S2SCLGADM', 0.005401198556215762),\n",
       " ('underrep', -0.0001246117965669757),\n",
       " ('S2SSKILLS', -0.005508108340929658),\n",
       " ('S2SUSECLG', -0.022652102977523732),\n",
       " ('S2SBORN', -0.04683959528031115),\n",
       " ('took_science_2012', -0.049052492080438895),\n",
       " ('S2SLEARN', -0.050040597034387214),\n",
       " ('X2POVERTY185', -0.05420493272318559),\n",
       " ('S2STCHRREC', -0.08698266793060622),\n",
       " ('S2SFRIEND', -0.08992561891171066),\n",
       " ('S2STUTORED', -0.09146014787535217),\n",
       " ('S2SBORING', -0.11372193254858771),\n",
       " ('S2SASSEXCL', -0.1271624087830965),\n",
       " ('S2STCHINTRST', -0.14195088616637788),\n",
       " ('S2STCHTREAT', -0.1495734071763719),\n",
       " ('S2SHSREQ', -0.16706890040894473),\n",
       " ('S2SWASTE', -0.17066223774985953),\n",
       " ('S2SENJOYING', -0.2337515067852211),\n",
       " ('S2SCNSLREC', -0.25243161938957714),\n",
       " ('S2STCHTHINK', -0.29944107316755475),\n",
       " ('S2SASSIGNED', -0.3249315947273672),\n",
       " ('S2SEMPREC', -0.5081183905346685),\n",
       " ('misc_class', -0.7007576033530316)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = dict(zip(list(features), list(lr_female_gs.coef_[0])))\n",
    "sorted_coef = sorted(coefs.items(), key=lambda kv: kv[1])\n",
    "sorted_coef.reverse()\n",
    "#coef_df = pd.DataFrame(data = sorted_dict, columns = ['feature', 'coefficient_value'])\n",
    "#coef_df\n",
    "sorted_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5865\n",
       "1     144\n",
       "Name: S2SEMPREC, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.S2SEMPREC.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=20),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(3, 8),\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'splitter': ['random', 'best']},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate classifier\n",
    "dtc_gs = DecisionTreeClassifier(random_state = 20)\n",
    "\n",
    "#create parameters for the gridsearch to search through\n",
    "param_dict={'max_depth': range(3,8),\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'splitter': ['random', 'best'],\n",
    "            'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "#create the gridsearch decision tree and fit it to the data to determine which will produce the best f1 score\n",
    "grid_tree=GridSearchCV(dtc_gs, \n",
    "                       param_dict, \n",
    "                       cv=10, \n",
    "                       scoring='f1', \n",
    "                       verbose=1, \n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=6, max_features='auto',\n",
       "                       random_state=20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dtcgs_test = grid_tree.best_estimator_.predict(X_test)\n",
    "pred_dtcgs_train = grid_tree.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_accuracy': 0.848346161847306,\n",
       " 'test_accuracy': 0.8502495840266223,\n",
       " 'train_precision': 0.6216216216216216,\n",
       " 'test_precision': 0.4838709677419355,\n",
       " 'train_recall': 0.12026143790849673,\n",
       " 'test_recall': 0.08379888268156424,\n",
       " 'train_f1': 0.2015334063526835,\n",
       " 'test_f1': 0.14285714285714288}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_dict['GridSearch_DecisionTree'] = {'train_accuracy': metrics.accuracy_score(y_train, pred_dtcgs_train),\n",
    "                                  'test_accuracy': metrics.accuracy_score(y_test, pred_dtcgs_test),\n",
    "                                  'train_precision':metrics.precision_score(y_train, pred_dtcgs_train),\n",
    "                                  'test_precision':metrics.precision_score(y_test, pred_dtcgs_test),\n",
    "                                  'train_recall':metrics.recall_score(y_train, pred_dtcgs_train),\n",
    "                                  'test_recall':metrics.recall_score(y_test, pred_dtcgs_test),\n",
    "                                  'train_f1':metrics.f1_score(y_train, pred_dtcgs_train),\n",
    "                                  'test_f1':metrics.f1_score(y_test, pred_dtcgs_test)}\n",
    "female_dict['GridSearch_DecisionTree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(C=0.66,\n",
       "                                                    class_weight='balanced',\n",
       "                                                    max_iter=125,\n",
       "                                                    random_state=20),\n",
       "                  n_estimators=5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "ds = DecisionTreeClassifier(criterion='entropy',max_depth=6)\n",
    "bag = BaggingClassifier(base_estimator = LogisticRegression(C = 0.66, class_weight = 'balanced', max_iter = 125, random_state = 20), max_samples=1.0,bootstrap=True, n_estimators = 5)\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = bag.predict(X_train)\n",
    "pred_test = bag.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43424317617866004"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3733333333333333"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
